{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5BkEUU-hGAx",
        "outputId": "07b10684-a9bf-4c52-ea2a-6a9d5699a04d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M = 20  # kg\\n\",\n",
        "g = 9.8 # m / s^2\\n\",\n",
        "m = 0.5 # kg\\n\",\n",
        "l = 0.5 # m\"\n",
        "v1 = ((M + m) * g) / (M * l)\n",
        "v2 = -(m * g) / M\n",
        "c1 = -1 / (M * l)\n",
        "c2 = 1 / M\n",
        "global A\n",
        "global B\n",
        "A = np.array([[0, 1, 0, 0], [0, 0, v2, 0], [0, 0, 0, 1], [0, 0, v1, 0]])\n",
        "B = np.array([[0], [c2], [0], [c1]])"
      ],
      "metadata": {
        "id": "laN0gzOJhs3r"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invertedpendulum(state,action):\n",
        "  state=np.array(state)\n",
        "  action=np.array(action)\n",
        "  state_gradient=np.dot(A,state.reshape(4,1))+np.dot(B,action-110)\n",
        "  state1=state+1e-2*state_gradient.reshape(4)\n",
        "  done=False\n",
        "  if(abs(state1[2])<np.pi/12):\n",
        "    reward=5\n",
        "  elif(abs(state1[2])<np.pi/10):\n",
        "    reward=4\n",
        "  elif(abs(state1[2])<np.pi/8):\n",
        "    reward=3\n",
        "  elif(abs(state1[2])<np.pi/6):\n",
        "    reward=2\n",
        "  elif(abs(state1[2])<np.pi/4):\n",
        "    reward=1\n",
        "  else:\n",
        "    reward=0\n",
        "    done=True\n",
        "  # print(state,action-100,state1)\n",
        "  return state1,reward,done\n"
      ],
      "metadata": {
        "id": "d06cG_iMhD2e"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEVICE=\"cuda:0\"\n",
        "ACTION_SPACE = np.arange(0,300)\n",
        "# ACTION_SPACE = [0,1]\n",
        "print(ACTION_SPACE)\n",
        "EPISODES = 30000\n",
        "STEPS = 1000\n",
        "GAMMA=1\n",
        "RENDER=False\n",
        "class ReinforceModel(nn.Module):\n",
        "    def __init__(self,num_action,num_input):\n",
        "        super(ReinforceModel,self).__init__()\n",
        "        self.num_action = num_action\n",
        "        self.num_input = num_input\n",
        "\n",
        "        self.layer1 = nn.Linear(num_input,64)\n",
        "        self.layer2 = nn.Linear(64,num_action)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = torch.tensor(x,dtype=torch.float32).unsqueeze(0)\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x=x.detach().numpy()\n",
        "        x = np.round(x, decimals=7)\n",
        "        x=torch.tensor(x)\n",
        "        actions = F.softmax(self.layer2(x))\n",
        "        try:\n",
        "          action = self.get_action(actions)\n",
        "        except:\n",
        "          print(x)\n",
        "          print(self.layer2.weight)\n",
        "          print(self.layer2(x))\n",
        "          actions=actions.detach().numpy()\n",
        "          actions[np.isnan(actions)] = 0\n",
        "          actions /= actions.sum()\n",
        "          print(actions)\n",
        "          actions=torch.tensor(actions)\n",
        "          action = self.get_action(actions)\n",
        "        a=torch.log(actions.squeeze(0))\n",
        "        log_prob_action = a[action]\n",
        "        return action,log_prob_action\n",
        "    def get_action(self,a):\n",
        "        return np.random.choice(ACTION_SPACE,p=a.squeeze(0).detach().cpu().numpy())\n",
        "    \n",
        "model = ReinforceModel(300,4)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "all_rewards =[]\n",
        "for episode in range(EPISODES):\n",
        "    done=False\n",
        " \n",
        "    state = [0,0,np.pi/6,0]\n",
        "    lp=[]\n",
        "    a=[]\n",
        "    r=[]\n",
        "    d=[]\n",
        "    s=[]\n",
        "\n",
        "    for step in range(STEPS):\n",
        "        action,log_prob = model(state)\n",
        "        # print(action)\n",
        "        # print(log_prob)\n",
        "        state,r_,done = invertedpendulum(state,action)\n",
        "        lp.append(log_prob)\n",
        "        r.append(r_)\n",
        "        if done:\n",
        "            all_rewards.append(np.sum(r))\n",
        "            if episode%100 ==0:\n",
        "                print(f\"EPISODE {episode} SCORE: {np.sum(r)} roll{pd.Series(all_rewards).tail(30).mean()}\")\n",
        "            \n",
        "            break\n",
        "    discounted_rewards = np.zeros_like(r)\n",
        "\n",
        "    discounted_rewards = []\n",
        "\n",
        "    for t in range(len(r)):\n",
        "        Gt = 0 \n",
        "        pw = 0\n",
        "        for r_ in r[t:]:\n",
        "            Gt = Gt + GAMMA**pw * r_\n",
        "            pw = pw + 1\n",
        "        discounted_rewards.append(Gt)\n",
        "    \n",
        "    discounted_rewards = np.array(discounted_rewards)\n",
        "        \n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "    discounted_rewards = torch.tensor(discounted_rewards,dtype=torch.float32)\n",
        "    discounted_rewards = (discounted_rewards - torch.mean(discounted_rewards))/ (torch.std(discounted_rewards))\n",
        "    log_prob = torch.stack(lp)\n",
        "    policy_gradient = -log_prob*discounted_rewards\n",
        "\n",
        "    model.zero_grad()\n",
        "    policy_gradient.sum().backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UarRCPiNUvPr",
        "outputId": "79898a3a-a9f3-4ce7-ef3a-0e17fcde1ec6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<ipython-input-71-233df94f3868>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  actions = F.softmax(self.layer2(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299]\n",
            "EPISODE 0 SCORE: 25 roll25.0\n",
            "EPISODE 100 SCORE: 23 roll28.733333333333334\n",
            "EPISODE 200 SCORE: 41 roll28.233333333333334\n",
            "EPISODE 300 SCORE: 29 roll30.2\n",
            "EPISODE 400 SCORE: 28 roll28.533333333333335\n",
            "EPISODE 500 SCORE: 29 roll30.5\n",
            "EPISODE 600 SCORE: 32 roll31.0\n",
            "EPISODE 700 SCORE: 28 roll27.766666666666666\n",
            "EPISODE 800 SCORE: 32 roll31.0\n",
            "EPISODE 900 SCORE: 35 roll30.9\n",
            "EPISODE 1000 SCORE: 27 roll30.1\n",
            "EPISODE 1100 SCORE: 25 roll30.8\n",
            "EPISODE 1200 SCORE: 37 roll30.633333333333333\n",
            "EPISODE 1300 SCORE: 25 roll31.666666666666668\n",
            "EPISODE 1400 SCORE: 30 roll33.766666666666666\n",
            "EPISODE 1500 SCORE: 28 roll30.233333333333334\n",
            "EPISODE 1600 SCORE: 31 roll30.9\n",
            "EPISODE 1700 SCORE: 30 roll33.46666666666667\n",
            "EPISODE 1800 SCORE: 31 roll33.53333333333333\n",
            "EPISODE 1900 SCORE: 28 roll34.63333333333333\n",
            "EPISODE 2000 SCORE: 36 roll38.86666666666667\n",
            "EPISODE 2100 SCORE: 28 roll38.9\n",
            "EPISODE 2200 SCORE: 26 roll33.333333333333336\n",
            "EPISODE 2300 SCORE: 45 roll35.733333333333334\n",
            "EPISODE 2400 SCORE: 24 roll49.56666666666667\n",
            "EPISODE 2500 SCORE: 49 roll39.6\n",
            "EPISODE 2600 SCORE: 34 roll47.93333333333333\n",
            "EPISODE 2700 SCORE: 33 roll45.833333333333336\n",
            "EPISODE 2800 SCORE: 39 roll66.76666666666667\n",
            "EPISODE 2900 SCORE: 34 roll56.63333333333333\n",
            "EPISODE 3000 SCORE: 38 roll76.5\n",
            "EPISODE 3100 SCORE: 47 roll89.4\n",
            "EPISODE 3200 SCORE: 40 roll117.96666666666667\n",
            "EPISODE 3300 SCORE: 66 roll136.13333333333333\n",
            "EPISODE 3400 SCORE: 55 roll104.06666666666666\n",
            "EPISODE 3500 SCORE: 336 roll129.6\n",
            "EPISODE 3600 SCORE: 46 roll167.16666666666666\n",
            "tensor([[0.0000, 0.7409, 0.1550, 0.5441, 0.0000, 0.2329, 0.0000, 0.3557, 0.0000,\n",
            "         0.0000, 0.7304, 0.4743, 0.0000, 0.0000, 0.4586, 0.0751, 0.0000, 0.0000,\n",
            "         0.0000, 0.2850, 0.2389, 0.6014, 0.3562, 0.0000, 0.0000, 0.0000, 0.1065,\n",
            "         0.4749, 0.2406, 0.0533, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6437,\n",
            "         0.0000, 0.0991, 0.0000, 0.2999, 0.0000, 0.0000, 0.0690, 0.0000, 0.4723,\n",
            "         0.0000, 0.0000, 0.2297, 0.5287, 0.0000, 0.4683, 0.0000, 0.0000, 0.0000,\n",
            "         0.6520, 0.4139, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000]])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0273,  0.0587,  0.1133,  ...,  0.1081,  0.3779, -0.0517],\n",
            "        [ 0.0757, -0.0220,  0.0026,  ...,  0.0358,  0.3037,  0.0037],\n",
            "        [ 0.0992,  0.0042,  0.0011,  ..., -0.0009,  0.1705,  0.1233],\n",
            "        ...,\n",
            "        [-0.0950, -0.0840, -0.1322,  ...,  0.0283,  0.0232, -0.0494],\n",
            "        [ 0.0596,  0.0687,  0.0873,  ...,  0.2192,  0.2127, -0.0392],\n",
            "        [-0.0176, -0.1179, -0.1081,  ...,  0.2790,  0.4862,  0.0973]],\n",
            "       requires_grad=True)\n",
            "tensor([[-2.6145e-01, -3.9548e-02, -7.2794e-01, -1.0674e+00, -1.0413e+00,\n",
            "         -6.4287e-01, -7.5961e-01, -4.0269e-01, -1.0192e+00, -5.3467e-01,\n",
            "         -8.7652e-01, -3.4582e-01,  6.3045e-01, -7.6595e-01,  1.6398e-01,\n",
            "         -8.6621e-01, -8.2126e-01, -8.6639e-01, -3.3750e-01, -4.6027e-01,\n",
            "          1.4646e-01, -3.4524e-01, -5.3283e-01, -8.5325e-02, -1.1970e+00,\n",
            "         -5.3853e-01, -2.7680e-03, -9.0337e-01, -1.6992e+00, -6.1972e-01,\n",
            "          2.6036e-01, -9.5082e-01,  3.4845e-01, -9.4051e-01, -1.3580e+00,\n",
            "         -5.1860e-01,  4.5203e-01, -4.4664e-01, -1.2021e+00, -1.0403e+00,\n",
            "         -6.7623e-01,  7.5422e-01, -8.8096e-02, -7.4097e-01, -1.1079e+00,\n",
            "         -4.4437e-02, -1.0471e+00, -4.2460e-01, -1.9241e-01, -1.2213e+00,\n",
            "         -1.6513e-01, -5.9020e-01, -6.4297e-01, -4.2891e-01, -4.1490e-01,\n",
            "          2.5605e-02, -9.9231e-01, -1.2337e+00, -4.7591e-01, -6.9120e-01,\n",
            "          1.9247e-01, -7.2588e-01, -4.6179e-01,  2.2640e-01, -5.6985e-01,\n",
            "         -3.0918e-01, -4.7330e-01, -5.8484e-01, -1.2202e+00, -6.0092e-01,\n",
            "         -8.1344e-01, -8.1084e-01, -9.8272e-02, -9.0745e-01, -6.6564e-02,\n",
            "         -1.0373e+00, -5.5418e-01, -1.0706e+00, -2.9220e-01, -4.5994e-01,\n",
            "         -5.0671e-01, -2.8375e-01,  4.6105e-02,  3.2794e-01,  1.3294e-01,\n",
            "         -1.6517e-01, -8.0689e-01,  4.2689e-01, -8.4094e-01, -6.8148e-01,\n",
            "         -6.4657e-01, -4.5623e-01, -8.9088e-02, -8.9264e-01, -1.2335e+00,\n",
            "          3.3892e-01, -4.1542e-01, -5.6194e-01, -1.2816e+00, -4.2154e-01,\n",
            "          2.7628e-01, -6.3510e-02, -8.3418e-01, -1.1263e+00,  4.1907e-02,\n",
            "         -7.7395e-01, -1.4122e-01, -3.2144e-01, -4.2590e-02, -2.9216e-01,\n",
            "          4.8302e-02, -3.3464e-01, -1.3925e-01, -1.9140e-01, -1.3076e+00,\n",
            "          5.2723e-01,  1.7166e-01, -7.1648e-01, -1.9618e-01, -5.3975e-01,\n",
            "          6.4691e-01,  1.0770e+00,  3.3352e-01,  1.8772e-02, -1.5740e-01,\n",
            "         -6.8303e-01,  1.1118e-01, -2.8314e-01, -1.6309e-02, -7.0386e-01,\n",
            "         -7.9093e-01,  6.4154e-01, -5.1641e-01,  8.5833e-03,  2.5019e-01,\n",
            "         -3.9233e-01, -3.4822e-01, -4.9652e-01, -8.5664e-01, -1.3416e+00,\n",
            "         -3.8361e-01,  1.3745e-01, -3.1396e-01,  1.2011e+00,  1.2342e-01,\n",
            "         -8.4032e-01, -3.4739e-01,  3.1075e-01,  3.5199e-01, -1.6471e-01,\n",
            "         -4.6638e-01, -1.7631e-01, -3.5270e-01, -7.6714e-01, -6.8740e-01,\n",
            "         -7.9686e-01, -1.0681e+00,  9.5858e-01, -4.8843e-01,  7.8750e-01,\n",
            "         -6.3371e-01, -4.8323e-01,  2.2919e-01,  2.1906e-01, -6.6122e-01,\n",
            "         -7.9130e-01,  6.3821e-01, -4.4939e-01,  2.0319e-01, -1.9623e-01,\n",
            "         -4.5264e-01,  4.7756e-01, -4.2972e-01, -1.0844e+00,  2.5094e-01,\n",
            "         -5.0344e-01,  2.8482e-01,  3.8085e-01, -9.3588e-01, -3.8101e-01,\n",
            "          2.5212e-01,  8.3211e-01,  7.8161e-01,  1.0701e+00, -7.1494e-01,\n",
            "         -1.1508e+00,  7.9589e-01,  6.5988e-01, -1.1893e+00,  4.4360e-02,\n",
            "         -3.4194e-01, -6.3645e-01, -2.9273e-01, -1.0895e+00,  1.6882e+00,\n",
            "          6.7827e-01, -9.1354e-01,  3.7108e-01,  1.9219e-01, -3.6921e-01,\n",
            "          6.1684e-01, -2.5494e-01,  1.1383e+00,  1.1136e+00, -6.0308e-01,\n",
            "         -8.7673e-01, -6.9178e-01, -1.9690e-01, -1.4434e+00, -2.8846e-01,\n",
            "          1.2592e+00,  1.6041e+00, -5.4658e-01,  1.9040e-01,  1.6807e+00,\n",
            "          5.2947e-01,  2.7653e+00,  1.2610e+00, -4.1658e-01,  7.3589e-01,\n",
            "          5.7910e-02,  5.3654e-01,  1.6981e+00, -6.2923e-01,  1.6559e-01,\n",
            "          3.1886e-01,  1.0258e+00,  4.9794e-01,  1.0501e-02,  1.3278e+00,\n",
            "          1.3108e+00, -4.0793e-02, -4.0502e-01,  2.0955e-01,  1.1474e-01,\n",
            "          5.2779e-01, -3.1217e-01,  2.7740e-01, -5.1819e-01, -6.1714e-01,\n",
            "          7.7729e-01,  2.0372e-01,  4.7444e-01,  3.1443e-01,  1.5233e-01,\n",
            "          4.4287e-01,  7.0267e-01, -8.0110e-01,  3.8595e-01, -1.6740e-01,\n",
            "         -3.3620e-02, -5.9413e-03, -4.3144e-01,  4.6740e-01,  7.3337e-01,\n",
            "         -8.7418e-02,  6.0369e-01,  3.0823e-02,  3.7900e-01,  7.3114e-01,\n",
            "         -1.9810e-02, -5.9459e-01,  1.5060e+00,  1.0655e+00, -3.7678e-01,\n",
            "         -3.9097e-01,  8.2261e-01, -4.4600e-01,  7.1310e-01,  2.1843e+00,\n",
            "         -9.0438e-01,  9.4582e-01,  1.0878e+00,  8.9001e-01,  2.5325e+00,\n",
            "          3.7311e-01,  1.0716e+00,  1.7999e-01, -1.5939e-01,  2.0358e+00,\n",
            "          1.4873e-01,  1.4395e+00,  1.5312e+00,  3.2230e+00, -3.6265e-01,\n",
            "          2.3089e+00,  6.3658e-01, -6.9987e-01,  8.7574e-02, -3.9275e-01,\n",
            "          7.9168e-01,  6.1384e-01,  2.3769e+00,  2.9259e-01, -2.3596e-01,\n",
            "         -6.5077e-01,  1.7016e+00, -7.5268e-01,  6.0465e-01, -5.8563e-01]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "[[0.00183848 0.00229525 0.0011531  0.00082122 0.00084288 0.00125548\n",
            "  0.00111715 0.00159632 0.00086171 0.00139894 0.00099389 0.00168973\n",
            "  0.00448544 0.00111009 0.00281334 0.00100419 0.00105035 0.00100401\n",
            "  0.00170385 0.001507   0.00276446 0.00169071 0.00140153 0.00219255\n",
            "  0.00072137 0.00139355 0.00238124 0.00096755 0.00043657 0.00128488\n",
            "  0.00309799 0.00092272 0.00338324 0.00093228 0.00061408 0.00142161\n",
            "  0.00375249 0.00152767 0.00071771 0.00084375 0.00121429 0.00507641\n",
            "  0.00218648 0.00113817 0.00078858 0.00228405 0.000838   0.00156173\n",
            "  0.0019699  0.00070405 0.00202437 0.00132338 0.00125536 0.00155501\n",
            "  0.00157694 0.00244977 0.00088522 0.0006954  0.00148361 0.00119625\n",
            "  0.00289464 0.00115547 0.00150471 0.00299454 0.00135058 0.00175279\n",
            "  0.00148749 0.00133049 0.00070481 0.00130927 0.0010586  0.00106136\n",
            "  0.00216434 0.00096362 0.00223407 0.0008463  0.00137191 0.00081855\n",
            "  0.00178281 0.0015075  0.00143862 0.00179793 0.00250051 0.00331456\n",
            "  0.00272735 0.0020243  0.00106556 0.00365932 0.00102989 0.00120793\n",
            "  0.00125084 0.00151309 0.00218431 0.00097799 0.00069552 0.00335115\n",
            "  0.00157613 0.00136132 0.00066283 0.0015665  0.00314769 0.0022409\n",
            "  0.00103687 0.00077421 0.00249003 0.00110124 0.00207336 0.00173144\n",
            "  0.00228828 0.00178287 0.00250601 0.00170873 0.00207745 0.00197188\n",
            "  0.00064587 0.00404557 0.00283503 0.00116639 0.00196249 0.00139186\n",
            "  0.00455991 0.00701034 0.00333313 0.00243309 0.00204009 0.00120606\n",
            "  0.00266863 0.00179902 0.00234921 0.0011812  0.0010827  0.00453549\n",
            "  0.00142473 0.00240842 0.00306664 0.00161293 0.00168567 0.00145335\n",
            "  0.00101384 0.00062424 0.00162708 0.00273967 0.00174443 0.00793673\n",
            "  0.0027015  0.00103053 0.00168708 0.00325807 0.00339524 0.00202522\n",
            "  0.00149781 0.00200187 0.00167815 0.00110877 0.0012008  0.0010763\n",
            "  0.00082059 0.00622748 0.00146515 0.00524822 0.00126704 0.0014728\n",
            "  0.00300291 0.00297264 0.00123265 0.0010823  0.0045204  0.00152348\n",
            "  0.00292584 0.00196237 0.00151853 0.00384952 0.00155374 0.00080736\n",
            "  0.00306893 0.00144332 0.00317469 0.00349466 0.00093661 0.0016313\n",
            "  0.00307256 0.00548765 0.00521742 0.00696227 0.00116818 0.0007555\n",
            "  0.00529242 0.00461943 0.00072698 0.00249615 0.0016963  0.00126357\n",
            "  0.00178186 0.00080324 0.01291741 0.00470514 0.00095777 0.00346069\n",
            "  0.00289382 0.00165067 0.00442483 0.00185049 0.00745365 0.00727136\n",
            "  0.00130644 0.00099368 0.00119556 0.00196106 0.00056384 0.00178949\n",
            "  0.0084113  0.01187619 0.00138238 0.00288865 0.01282103 0.00405462\n",
            "  0.03792665 0.00842635 0.0015743  0.00498423 0.0025302  0.00408341\n",
            "  0.01304601 0.00127272 0.00281785 0.0032846  0.00666061 0.00392876\n",
            "  0.00241305 0.00900896 0.00885647 0.00229239 0.00159261 0.00294449\n",
            "  0.00267815 0.00404784 0.00174756 0.00315122 0.00142219 0.0012882\n",
            "  0.00519488 0.00292739 0.00383753 0.0032701  0.00278074 0.00371828\n",
            "  0.00482137 0.00107175 0.00351254 0.00201978 0.00230889 0.00237369\n",
            "  0.00155107 0.00381062 0.00497166 0.00218796 0.00436701 0.00246259\n",
            "  0.00348822 0.0049606  0.002341   0.00131759 0.0107664  0.00692994\n",
            "  0.00163821 0.00161514 0.00543574 0.00152866 0.00487194 0.02121364\n",
            "  0.00096658 0.00614848 0.00708671 0.00581478 0.03005164 0.00346771\n",
            "  0.00697279 0.00285873 0.00203602 0.01828787 0.00277075 0.01007297\n",
            "  0.01104053 0.05994283 0.00166154 0.02403068 0.00451303 0.00118592\n",
            "  0.00260638 0.00161226 0.00527021 0.00441155 0.02571949 0.00319944\n",
            "  0.00188594 0.0012456  0.0130912  0.00112491 0.00437122 0.00132945]]\n",
            "EPISODE 3700 SCORE: 280 roll185.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-233df94f3868>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# env.render()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# print(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;31m# print(action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# print(log_prob)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-233df94f3868>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rewards=[]\n",
        "state = [0,0,np.pi/6,0]\n",
        "done=False\n",
        "while(done==False):\n",
        "    action,log_prob = model(state)\n",
        "    print(state)\n",
        "    state,reward,done = invertedpendulum(state,action)\n",
        "    rewards.append(reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoaXCgn0wsjp",
        "outputId": "371483fa-3632-4da8-a778-c12afd1a7328"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-c6ec04f81e10>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  actions = F.softmax(self.layer2(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0.5235987755982988, 0]\n",
            "[ 0.          0.11371718  0.52359878 -0.12480901]\n",
            "[0.00113717 0.08743437 0.52235069 0.03038199]\n",
            "[0.00201152 0.06115461 0.52265451 0.18532224]\n",
            "[0.00262306 0.1748741  0.52450773 0.06032353]\n",
            "[0.0043718  0.14858906 0.52511096 0.21569713]\n",
            "[0.00585769 0.12230254 0.52726793 0.37119193]\n",
            "[0.00708072 0.23601073 0.53097985 0.24712005]\n",
            "[0.00944083 0.20970983 0.53345105 0.40379391]\n",
            "[0.01153792 0.32340288 0.53748899 0.28096422]\n",
            "[0.01477195 0.29708603 0.54029864 0.43894576]\n",
            "[0.01774281 0.4107623  0.54468809 0.31749176]\n",
            "[0.02185044 0.53342781 0.54786301 0.1789196 ]\n",
            "[0.02718471 0.65608555 0.54965221 0.04098527]\n",
            "[0.03374557 0.6297389  0.55006206 0.2014104 ]\n",
            "[0.04004296 0.75239125 0.55207616 0.06391787]\n",
            "[ 0.04756687  0.86603866  0.55271534 -0.05517003]\n",
            "[ 0.05622726  0.97968451  0.55216364 -0.17412952]\n",
            "[ 0.0660241   0.95333171  0.55042235 -0.01319984]\n",
            "[0.07555742 0.92698317 0.55029035 0.14738001]\n",
            "[0.08482725 0.90063496 0.55176415 0.30793334]\n",
            "[0.0938336  1.00678314 0.55484348 0.20378276]\n",
            "[0.10390143 1.12942377 0.55688131 0.06725081]\n",
            "[0.11519567 1.10305941 0.55755382 0.22912827]\n",
            "[0.12622626 1.2256934  0.5598451  0.09314083]\n",
            "[0.1384832  1.19932178 0.56077651 0.25561371]\n",
            "[0.15047642 1.32194788 0.56333265 0.12027371]\n",
            "[0.1636959  1.29556772 0.56453538 0.28344724]\n",
            "[0.17665157 1.2691846  0.56736986 0.4468624 ]\n",
            "[0.18934342 1.39179455 0.57183848 0.312847  ]\n",
            "[0.20326136 1.36539354 0.57496695 0.47772935]\n",
            "[0.2169153  1.48798488 0.57974424 0.34524021]\n",
            "[0.23179515 1.4615645  0.58319664 0.51171083]\n",
            "[0.24641079 1.57513567 0.58831375 0.39887504]\n",
            "[0.26216215 1.6976943  0.5923025  0.26906727]\n",
            "[0.27913909 1.67124316 0.59499318 0.43806084]\n",
            "[0.29585152 1.79378543 0.59937378 0.30959497]\n",
            "[0.31378938 1.91631696 0.60246973 0.18200917]\n",
            "[0.33295255 1.88984091 0.60428983 0.35304534]\n",
            "[0.35185096 2.0123604  0.60782028 0.22644716]\n",
            "[0.37197456 1.98587124 0.61008475 0.39855826]\n",
            "[0.39183327 2.10837653 0.61407033 0.27312428]\n",
            "[0.41291704 2.08187206 0.61680158 0.44649101]\n",
            "[0.43373576 2.2043609  0.62126649 0.32240645]\n",
            "[0.45577937 2.32683879 0.62449055 0.19921889]\n",
            "[0.47904776 2.44930879 0.62648274 0.07667904]\n",
            "[0.50354084 2.42277391 0.62724953 0.25253942]\n",
            "[0.52776858 2.53623715 0.62977492 0.14855385]\n",
            "[0.55313096 2.6586942  0.63126046 0.02707563]\n",
            "[ 0.5797179   2.78114761  0.63153122 -0.09410414]\n",
            "[ 0.60752937  2.90360036  0.63059018 -0.21522952]\n",
            "[ 0.63656538  3.01705541  0.62843788 -0.31854395]\n",
            "[ 0.66673593  3.13951574  0.62525244 -0.44029078]\n",
            "[ 0.69813109  3.26198387  0.62084954 -0.56267756]\n",
            "[ 0.73075093  3.38446279  0.61522276 -0.68594889]\n",
            "[ 0.76459555  3.3579555   0.60836327 -0.51235064]\n",
            "[ 0.79817511  3.33146501  0.60323976 -0.34013046]\n",
            "[ 0.83148976  3.30498707  0.59983846 -0.16893959]\n",
            "[ 0.86453963  3.42751746  0.59814906 -0.29643204]\n",
            "[ 0.89881481  3.550052    0.59518474 -0.4242639 ]\n",
            "[ 0.93431533  3.6725938   0.5909421  -0.55269128]\n",
            "[ 0.97104126  3.79514599  0.58541519 -0.68197101]\n",
            "[ 1.00899272  3.91771172  0.57859548 -0.8123611 ]\n",
            "[ 1.04816984  4.04029416  0.57047187 -0.94412127]\n",
            "[ 1.08857278  4.01389651  0.56103066 -0.77951347]\n",
            "[ 1.12871175  4.13652198  0.55323552 -0.91480241]\n",
            "[ 1.17007697  4.11016655  0.5440875  -0.75365739]\n",
            "[ 1.21117863  4.08383354  0.53655093 -0.59435022]\n",
            "[ 1.25201697  4.05751899  0.53060742 -0.43655713]\n",
            "[ 1.29259216  4.031219    0.52624185 -0.2799581 ]\n",
            "[ 1.33290435  4.00492971  0.52344227 -0.12423612]\n",
            "[1.37295364 3.97864728 0.52219991 0.03092344]\n",
            "[1.41274012 3.95236789 0.52250914 0.1858334 ]\n",
            "[1.4522638  4.07508774 0.52436748 0.04280549]\n",
            "[ 1.49301467  4.19780304  0.52479553 -0.09984909]\n",
            "[ 1.5349927   4.32051729  0.52379704 -0.24241767]\n",
            "[ 1.57819788  4.29423399  0.52137287 -0.08718684]\n",
            "[1.62114022 4.26795662 0.520501   0.06755697]\n",
            "[ 1.66381978  4.39068139  0.52117657 -0.07587438]\n",
            "[ 1.7077266   4.51340451  0.52041782 -0.21917001]\n",
            "[ 1.75286064  4.48712949  0.51822612 -0.06461807]\n",
            "[ 1.79773194  4.60985983  0.51757994 -0.20850644]\n",
            "[ 1.84383054  4.58359176  0.51549488 -0.05452463]\n",
            "[ 1.88966645  4.7063288   0.51494963 -0.19896171]\n",
            "[ 1.93672974  4.82906717  0.51296001 -0.34350833]\n",
            "[ 1.98502041  4.95181042  0.50952493 -0.48845466]\n",
            "[ 2.03453852  4.92556209  0.50464038 -0.3360911 ]\n",
            "[ 2.08379414  4.89932572  0.50127947 -0.18470885]\n",
            "[ 2.1327874   5.02209758  0.49943238 -0.3320018 ]\n",
            "[ 2.18300837  5.14487397  0.49611237 -0.47966584]\n",
            "[ 2.23445711  5.2676585   0.49131571 -0.62799686]\n",
            "[ 2.2871337   5.39045477  0.48503574 -0.77729154]\n",
            "[ 2.34103824  5.51326644  0.47726282 -0.92784786]\n",
            "[ 2.39617091  5.48709714  0.46798435 -0.78196576]\n",
            "[ 2.45104188  5.46095058  0.46016469 -0.6379477 ]\n",
            "[ 2.50565138  5.58382318  0.45378521 -0.79350062]\n",
            "[ 2.56148962  5.5577114   0.4458502  -0.65233517]\n",
            "[ 2.61706673  5.53161907  0.43932685 -0.51276386]\n",
            "[ 2.67238292  5.50554272  0.43419921 -0.3745031 ]\n",
            "[ 2.72743835  5.47947893  0.43045418 -0.23727247]\n",
            "[ 2.78223314  5.60242432  0.42808146 -0.39879423]\n",
            "[ 2.83825738  5.72537552  0.42409352 -0.56079266]\n",
            "[ 2.89551114  5.69933649  0.41848559 -0.42559228]\n",
            "[ 2.9525045   5.8223112   0.41422967 -0.58951852]\n",
            "[ 3.01072761  5.94529634  0.40833448 -0.75429978]\n",
            "[ 3.07018058  6.06829592  0.40079148 -0.92026538]\n",
            "[ 3.13086354  6.04231398  0.39158883 -0.78974637]\n",
            "[ 3.19128668  6.16535459  0.38369137 -0.95907618]\n",
            "[ 3.25294022  6.13941454  0.3741006  -0.83199258]\n",
            "[ 3.31433437  6.262498    0.36578068 -1.00483577]\n",
            "[ 3.37695935  6.38560183  0.35573232 -1.17935043]\n",
            "[ 3.44081537  6.35973029  0.34393882 -1.05788381]\n",
            "[ 3.50441267  6.33388764  0.33335998 -0.9387865 ]\n",
            "[ 3.56775154  6.30807091  0.32397211 -0.82181448]\n",
            "[ 3.63083225  6.28727718  0.31575397 -0.71672848]\n",
            "[ 3.69370503  6.41050358  0.30858668 -0.90129351]\n",
            "[ 3.75781006  6.38474754  0.29957375 -0.78929845]\n",
            "[ 3.82165754  6.35901359  0.29168076 -0.67911408]\n",
            "[ 3.88524767  6.48229897  0.28488962 -0.86851541]\n",
            "[ 3.95007066  6.45660099  0.27620447 -0.76128109]\n",
            "[ 4.01463667  6.43092429  0.26859166 -0.65579161]\n",
            "[ 4.07894592  6.40526624  0.26203374 -0.55183155]\n",
            "[ 4.14299858  6.52862426  0.25651543 -0.74718897]\n",
            "[ 4.20828482  6.50299579  0.24904354 -0.64565502]\n",
            "[ 4.27331478  6.47738564  0.24258699 -0.54562217]\n",
            "[ 4.33808863  6.6007913   0.23713077 -0.74488645]\n",
            "[ 4.40409655  6.67821033  0.2296819  -0.85324687]\n",
            "[ 4.47087865  6.80164761  0.22114943 -1.05510378]\n",
            "[ 4.53889513  6.77610579  0.21059839 -0.96067486]\n",
            "[ 4.60665618  6.75058982  0.20099165 -0.86836564]\n",
            "[ 4.67416208  6.8740974   0.19230799 -1.07598642]\n",
            "[ 4.74290306  6.84862624  0.18154813 -0.98735174]\n",
            "[ 4.81138932  6.82318145  0.17167461 -0.90087873]\n",
            "[ 4.87962113  6.79776085  0.16266582 -0.8163893 ]\n",
            "[ 4.94759874  6.92136231  0.15450193 -1.03170973]\n",
            "[ 5.01681237  6.89598378  0.14418483 -0.9506703 ]\n",
            "[ 5.0857722   6.87063053  0.13467813 -0.87170356]\n",
            "[ 5.15447851  6.99430057  0.12596109 -1.09264673]\n",
            "[ 5.22442151  6.96899197  0.11503462 -1.01734115]\n",
            "[ 5.29411143  7.09271013  0.10486121 -1.24223069]\n",
            "[ 5.36503853  7.06745322  0.09243891 -1.17116407]\n",
            "[ 5.43571307  7.04222675  0.08072727 -1.1025931 ]\n",
            "[ 5.50613533  7.01702896  0.06970133 -1.03637499]\n",
            "[ 5.57630562  6.99185819  0.05933758 -0.97237199]\n",
            "[ 5.64622421  7.11571282  0.04961386 -1.20845107]\n",
            "[ 5.71738133  7.09059126  0.03752935 -1.14848364]\n",
            "[ 5.78828725  7.06549932  0.02604452 -1.090944  ]\n",
            "[ 5.85894224  7.04043551  0.01513508 -1.03571165]\n",
            "[ 5.92934660e+00  7.01539843e+00  4.77796128e-03 -9.82671015e-01]\n",
            "[ 5.99950058e+00  6.99038672e+00 -5.04874887e-03 -9.31711123e-01]\n",
            "[ 6.06940445  6.96539909 -0.01436586 -0.88272542]\n",
            "[ 6.13905844  7.08943429 -0.02319311 -1.13361152]\n",
            "[ 6.20995278  7.06449111 -0.03452923 -1.08827101]\n",
            "[ 6.28059769  7.03957571 -0.04541194 -1.04520794]\n",
            "[ 6.35099345  7.01468697 -0.05586402 -1.0043312 ]\n",
            "[ 6.42114032  6.98982383 -0.06590733 -0.96555428]\n",
            "[ 6.49103856  6.96498531 -0.07556287 -0.92879506]\n",
            "[ 6.56068841  6.94017043 -0.08485082 -0.89397564]\n",
            "[ 6.63009011  6.91537832 -0.09379058 -0.86102217]\n",
            "[ 6.6992439   6.89060811 -0.1024008  -0.8298647 ]\n",
            "[ 6.76814998  6.86585899 -0.11069945 -0.80043702]\n",
            "[ 6.83680857  6.9901302  -0.11870382 -1.07067654]\n",
            "[ 6.90670987  7.11442103 -0.12941058 -1.34252414]\n",
            "[ 6.97785408  7.08973808 -0.14283583 -1.31852272]\n",
            "[ 7.04875146  7.11158803 -0.15602105 -1.39021844]\n",
            "[ 7.11986734  7.23597028 -0.16992324 -1.66956307]\n",
            "[ 7.19222704  7.21138659 -0.18661887 -1.65370065]\n",
            "[ 7.26434091  7.18684381 -0.20315588 -1.64119238]\n",
            "[ 7.33620935  7.16234154 -0.2195678  -1.6320064 ]\n",
            "[ 7.40783276  7.13787948 -0.23588786 -1.62611757]\n",
            "[ 7.47921156  7.11345741 -0.25214904 -1.62350744]\n",
            "[ 7.55034613  7.08907517 -0.26838411 -1.62416418]\n",
            "[ 7.62123688  7.06473271 -0.28462575 -1.62808255]\n",
            "[ 7.69188421  7.04043005 -0.30090658 -1.63526386]\n",
            "[ 7.76228851  7.01616727 -0.31725922 -1.64571599]\n",
            "[ 7.83245018  6.99194455 -0.33371638 -1.65945337]\n",
            "[ 7.90236963  6.96776216 -0.35031091 -1.67649699]\n",
            "[ 7.97204725  6.94362042 -0.36707588 -1.69687445]\n",
            "[ 8.04148346  6.91951976 -0.38404463 -1.72062   ]\n",
            "[ 8.11067865  6.89546067 -0.40125083 -1.74777456]\n",
            "[ 8.17963326  6.87144373 -0.41872857 -1.77838586]\n",
            "[ 8.2483477   6.85046961 -0.43651243 -1.81850843]\n",
            "[ 8.31685239  6.82653907 -0.45469752 -1.85620377]\n",
            "[ 8.38511778  6.80265308 -0.47325955 -1.8975525 ]\n",
            "[ 8.45314432  6.77881257 -0.49223508 -1.94263035]\n",
            "[ 8.52093244  6.75501854 -0.51166138 -1.99152038]\n",
            "[ 8.58848263  6.73127211 -0.53157659 -2.04431315]\n",
            "[ 8.65579535  6.70757447 -0.55201972 -2.10110688]\n",
            "[ 8.72287109  6.68392692 -0.57303079 -2.16200764]\n",
            "[ 8.78971036  6.66033085 -0.59465086 -2.22712953]\n",
            "[ 8.85631367  6.63678774 -0.61692216 -2.29659489]\n",
            "[ 8.92268155  6.6132992  -0.63988811 -2.37053455]\n",
            "[ 8.98881454  6.58986693 -0.66359345 -2.44908807]\n",
            "[ 9.05471321  6.56649273 -0.68808433 -2.53240399]\n",
            "[ 9.12037814  6.54317854 -0.71340837 -2.62064014]\n",
            "[ 9.18580992  6.51992639 -0.73961477 -2.71396388]\n",
            "[ 9.25100919  6.49673844 -0.76675441 -2.81255249]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rewards,len(rewards))"
      ],
      "metadata": {
        "id": "uwj46TZ7541g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# actions=[1,2,3,4,5]\n",
        "# print(min(actions),max(actions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNx3la1eKNt9",
        "outputId": "4e38d823-db08-45db-b6d9-218b9ec6778b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A=[]\n",
        "x=1\n",
        "for i in range(1000):\n",
        "  A.append(x/10.0)\n",
        "  x=x/10.0\n",
        "A=np.array(A)\n",
        "A[np.isnan(A)] = 0\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T_wzZnPiJQe",
        "outputId": "10440a34-f5a8-4f41-921a-45ea78cc090c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.000000e-001 1.000000e-002 1.000000e-003 1.000000e-004 1.000000e-005\n",
            " 1.000000e-006 1.000000e-007 1.000000e-008 1.000000e-009 1.000000e-010\n",
            " 1.000000e-011 1.000000e-012 1.000000e-013 1.000000e-014 1.000000e-015\n",
            " 1.000000e-016 1.000000e-017 1.000000e-018 1.000000e-019 1.000000e-020\n",
            " 1.000000e-021 1.000000e-022 1.000000e-023 1.000000e-024 1.000000e-025\n",
            " 1.000000e-026 1.000000e-027 1.000000e-028 1.000000e-029 1.000000e-030\n",
            " 1.000000e-031 1.000000e-032 1.000000e-033 1.000000e-034 1.000000e-035\n",
            " 1.000000e-036 1.000000e-037 1.000000e-038 1.000000e-039 1.000000e-040\n",
            " 1.000000e-041 1.000000e-042 1.000000e-043 1.000000e-044 1.000000e-045\n",
            " 1.000000e-046 1.000000e-047 1.000000e-048 1.000000e-049 1.000000e-050\n",
            " 1.000000e-051 1.000000e-052 1.000000e-053 1.000000e-054 1.000000e-055\n",
            " 1.000000e-056 1.000000e-057 1.000000e-058 1.000000e-059 1.000000e-060\n",
            " 1.000000e-061 1.000000e-062 1.000000e-063 1.000000e-064 1.000000e-065\n",
            " 1.000000e-066 1.000000e-067 1.000000e-068 1.000000e-069 1.000000e-070\n",
            " 1.000000e-071 1.000000e-072 1.000000e-073 1.000000e-074 1.000000e-075\n",
            " 1.000000e-076 1.000000e-077 1.000000e-078 1.000000e-079 1.000000e-080\n",
            " 1.000000e-081 1.000000e-082 1.000000e-083 1.000000e-084 1.000000e-085\n",
            " 1.000000e-086 1.000000e-087 1.000000e-088 1.000000e-089 1.000000e-090\n",
            " 1.000000e-091 1.000000e-092 1.000000e-093 1.000000e-094 1.000000e-095\n",
            " 1.000000e-096 1.000000e-097 1.000000e-098 1.000000e-099 1.000000e-100\n",
            " 1.000000e-101 1.000000e-102 1.000000e-103 1.000000e-104 1.000000e-105\n",
            " 1.000000e-106 1.000000e-107 1.000000e-108 1.000000e-109 1.000000e-110\n",
            " 1.000000e-111 1.000000e-112 1.000000e-113 1.000000e-114 1.000000e-115\n",
            " 1.000000e-116 1.000000e-117 1.000000e-118 1.000000e-119 1.000000e-120\n",
            " 1.000000e-121 1.000000e-122 1.000000e-123 1.000000e-124 1.000000e-125\n",
            " 1.000000e-126 1.000000e-127 1.000000e-128 1.000000e-129 1.000000e-130\n",
            " 1.000000e-131 1.000000e-132 1.000000e-133 1.000000e-134 1.000000e-135\n",
            " 1.000000e-136 1.000000e-137 1.000000e-138 1.000000e-139 1.000000e-140\n",
            " 1.000000e-141 1.000000e-142 1.000000e-143 1.000000e-144 1.000000e-145\n",
            " 1.000000e-146 1.000000e-147 1.000000e-148 1.000000e-149 1.000000e-150\n",
            " 1.000000e-151 1.000000e-152 1.000000e-153 1.000000e-154 1.000000e-155\n",
            " 1.000000e-156 1.000000e-157 1.000000e-158 1.000000e-159 1.000000e-160\n",
            " 1.000000e-161 1.000000e-162 1.000000e-163 1.000000e-164 1.000000e-165\n",
            " 1.000000e-166 1.000000e-167 1.000000e-168 1.000000e-169 1.000000e-170\n",
            " 1.000000e-171 1.000000e-172 1.000000e-173 1.000000e-174 1.000000e-175\n",
            " 1.000000e-176 1.000000e-177 1.000000e-178 1.000000e-179 1.000000e-180\n",
            " 1.000000e-181 1.000000e-182 1.000000e-183 1.000000e-184 1.000000e-185\n",
            " 1.000000e-186 1.000000e-187 1.000000e-188 1.000000e-189 1.000000e-190\n",
            " 1.000000e-191 1.000000e-192 1.000000e-193 1.000000e-194 1.000000e-195\n",
            " 1.000000e-196 1.000000e-197 1.000000e-198 1.000000e-199 1.000000e-200\n",
            " 1.000000e-201 1.000000e-202 1.000000e-203 1.000000e-204 1.000000e-205\n",
            " 1.000000e-206 1.000000e-207 1.000000e-208 1.000000e-209 1.000000e-210\n",
            " 1.000000e-211 1.000000e-212 1.000000e-213 1.000000e-214 1.000000e-215\n",
            " 1.000000e-216 1.000000e-217 1.000000e-218 1.000000e-219 1.000000e-220\n",
            " 1.000000e-221 1.000000e-222 1.000000e-223 1.000000e-224 1.000000e-225\n",
            " 1.000000e-226 1.000000e-227 1.000000e-228 1.000000e-229 1.000000e-230\n",
            " 1.000000e-231 1.000000e-232 1.000000e-233 1.000000e-234 1.000000e-235\n",
            " 1.000000e-236 1.000000e-237 1.000000e-238 1.000000e-239 1.000000e-240\n",
            " 1.000000e-241 1.000000e-242 1.000000e-243 1.000000e-244 1.000000e-245\n",
            " 1.000000e-246 1.000000e-247 1.000000e-248 1.000000e-249 1.000000e-250\n",
            " 1.000000e-251 1.000000e-252 1.000000e-253 1.000000e-254 1.000000e-255\n",
            " 1.000000e-256 1.000000e-257 1.000000e-258 1.000000e-259 1.000000e-260\n",
            " 1.000000e-261 1.000000e-262 1.000000e-263 1.000000e-264 1.000000e-265\n",
            " 1.000000e-266 1.000000e-267 1.000000e-268 1.000000e-269 1.000000e-270\n",
            " 1.000000e-271 1.000000e-272 1.000000e-273 1.000000e-274 1.000000e-275\n",
            " 1.000000e-276 1.000000e-277 1.000000e-278 1.000000e-279 1.000000e-280\n",
            " 1.000000e-281 1.000000e-282 1.000000e-283 1.000000e-284 1.000000e-285\n",
            " 1.000000e-286 1.000000e-287 1.000000e-288 1.000000e-289 1.000000e-290\n",
            " 1.000000e-291 1.000000e-292 1.000000e-293 1.000000e-294 1.000000e-295\n",
            " 1.000000e-296 1.000000e-297 1.000000e-298 1.000000e-299 1.000000e-300\n",
            " 1.000000e-301 1.000000e-302 1.000000e-303 1.000000e-304 1.000000e-305\n",
            " 1.000000e-306 1.000000e-307 1.000000e-308 1.000000e-309 1.000000e-310\n",
            " 1.000000e-311 1.000000e-312 1.000000e-313 1.000000e-314 1.000000e-315\n",
            " 1.000000e-316 9.999997e-318 9.999987e-319 9.999889e-320 9.999889e-321\n",
            " 9.980126e-322 9.881313e-323 9.881313e-324 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000\n",
            " 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000 0.000000e+000]\n"
          ]
        }
      ]
    }
  ]
}